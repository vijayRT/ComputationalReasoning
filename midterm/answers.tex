\documentclass[UTF8]{article}
\usepackage{geometry}
\usepackage{mathrsfs,amsmath}
\usepackage{amssymb}
\usepackage{mathbbol}
\usepackage{enumerate}
\usepackage{needspace}
\usepackage{graphicx}
\usepackage{titlesec}
\setcounter{secnumdepth}{4}
\graphicspath{{./images}}
\newcommand{\mycite}[1]{\textbf{\textit{#1}}}
\newcommand{\opinion}[5]{$\omega_{#1} = (#2, #3, #4, #5)$}
\begin{document}
    
\title{COMP 8920 Section 02\\ Computational Reasoning in AI \\Midterm}
\author{
    Vijay Rajasekar Thirulokachander \\
    \large 105092311 \\
    \large thirulo@uwindsor.ca
}
\maketitle
\date{}


\section{Binary Division Constraint Derivation}
\subsection{Deriving $d_x \geq d_y$}
Given,
$$
d_{x \overline{\land} y} = \frac{d_x - d_y}{1 - d_y}
$$
If $d_{x \overline{\land} y} = 0$
$$
0 = \frac{d_x - d_y}{1 - d_y}
$$
$$
\Rightarrow \frac{d_y}{1 - d_y} = \frac{d_x}{1-d_y}
$$
$$
\Rightarrow d_x = d_yx
$$

Since $0 \leq d_{x \overline{\land} y} \leq 1$, and $d_x = d_y$ for the lowest possible value of $0 \leq d_{x \overline{\land} y}$, therefore

$$
d_x \geq d_y
$$
\subsection{Deriving $a_x < a_y$}
Given,
$$
b_{x \overline{\land} y} = \frac{a_y(b_x + a_xu_x)}{(a_y - a_x)(b_y + a_yu_y)} - \frac{a_x (1 - d_x)}{(a_y - a_x)(1 - d_y)}
$$
If $a_x \geq a_y$
$$
b_{x \overline{\land} y} = \frac{a_y(b_x + a_xu_x)}{\infty(b_y + a_yu_y)} - \frac{a_x (1 - d_x)}{\infty(1 - d_y)}
$$
which is clearly undefined.
Therefore, $a_x < a_y$
\section{Defintions of concepts and their applications in reasoning}
\subsection{Probability Measure}

Out of the many approaches to represent belief and uncertainty, probability has the advantage of being well understood.  It is a powerful tool; many technical results have been proved that facilitate its use, and a number of arguments suggest that, under certain assumptions (whose reasonableness can be debated) probability is the only “rational” way to represent uncertainty. [Lecture Slides 1B]\\

Consider now a completely arbitrary nonempty set of possible outcomes to be $\Omega$ . A class $\mathcal{F}$ of
subsets of $\Omega$ is called a field if it contains $\Omega$ itself and is closed under the
formation of complements and finite unions: 
\begin{enumerate}[i]
    \item $ \Omega \in \mathcal{F}$
    \item $A \in \mathcal{F} $ implies $\neg A \in \mathcal{F}$ 
    \item $ A, B \in \mathcal{F}$ implies $A \cup B \in \mathcal{F}$
    
\end{enumerate}
A set function is a real-valued function defined on some class of subsets of
$ \Omega $. A set function P on a field  $ \mathcal{F}$ is a \textit{probability measure} if it satisfies these
conditions:
\begin{enumerate}[i]
    \item $ 0< P(A)< 1 $ for $ A \in \mathcal{F} $
    \item $ P(\emptyset) = 0, P(\Omega) = 1 $
    \item if $ A_1, A_2, ... $ is a disjoint sequence of $ \mathcal{F} $ sets and if $ \cup^\infty_{k=1} \in \mathcal{F}$ i.e the union of all sequences of $\mathcal{F} $ sets belongs to $\mathcal{F}$ then
    $$ P \left( \bigcup_{k = 1}^{\infty} A_k \right) = \sum_{k=1}^{\infty} P(A_k) $$ i.e the probability of the union of all disjoint sequences is equal to the sum of probability of each disjoint sequence. This property is referred to as \textit{finite additivity}.
\end{enumerate}
The above definitions were obtained from the book \mycite{Probability and Measure, Third Edition, Patrick Billingsley, Pg. 19 - 23}

[https://www.colorado.edu/amath/sites/default/files/attached-files/billingsley.pdf] \\

Sets of probability measures have many of the advantages of probability, and may be more appropriate in a setting where there is uncertainty about the likelihood.  Considering sets of weighted probability measures allows for more flexible modeling, but has the disadvantage of needing yet more numbers to characterize a situation.

\subsection{Belief Function}
Belief in a set of elements, say A, of a frame $\theta$, represents the total belief that one has
based on the evidence obtained. It is the sum of all the belief masses assigned to elements that
are contained in the set A and the belief mass assigned to the set A. Mathematically, one can
express the total belief in the set A as $$ Bel(A) = \sum_{B \subseteq A} m(B) $$ Unlike probability theory, Bel(A) = 0
represents lack of evidence about A, while P(A) = 0 represents the impossibility of A. However,
Bel(A) = 1 represents certainty, that is A is certain to occur, similar to P(A) = 1, which also
represents the certainty that A is true. \mycite{[Srivastava, Rajendra P.. “The Dempster-Shafer Theory of Belief Functions for Managing Uncertainties : An Introduction and Fraud Risk Assessment Illustration 1.” (2012).]}

Prof. Judea Pearl, in his work \mycite{Reasoning with Belief Functions: An Analysis of Compatibility}, provides three domains of reasoning in which belief functions are applied:
\begin{enumerate}[i]
    \item \textit{Representation of incomplete knowledge}: In cases where fully specified
    probabilistic knowledge is not available, belief functions are often used to
    represent states of partial knowledge, with Bel(A) interpreted as a strength
    of arguments in favor of A.
    \item  \textit{Belief updating}: Belief functions offer a method of assimilating the impact
    of new evidence into a state of partial knowledge or partial belief.
    \item \textit{Pooling of evidence}: When multiple pieces of evidence are available, the
    BF combination method provides a faithful summary of the information
    carried by all the individual pieces. The method consists of encoding each
    piece of evidence as a belief function and combining these functions by
    Dempster's rule of orthogonal sum.
\end{enumerate}
\subsection{Conditional Probability}
Before defining conditional probability, we need to define what \textit{unconditional probability} is. The unconditional or prior probability associated with a proposition A is the degree of belief accorded to it in the absence of any information. It is written as P(A).
However, once the agent has obtained some evidence concerning a previously unknown variable, prior probability no longer applies. Instead we use conditional probability. The notation $P(A|B)$ denotes "probability of A, given all that we know is B". \mycite{[Lecture Slides 1B]}

Conditional inference plays a central role in logical and Bayesian
reasoning, and is used in a wide range of applications. It basically consists of expressing conditional relationship between
parent and child propositions, and then to combine those conditionals with evidence about the parent propositions in order to
infer conclusions about the child propositions. Probabilistic conditional reasoning is used extensively in areas where conclusions need to be derived from probabilistic input evidence, such as for making
diagnoses from medical tests. \mycite{[Conditional Reasoning with Subjective Logic, Audun Jøsang]}

\subsection{Probabilistic Reasoning}
Probability theory has existed in one form or another for several hundred years.
During this time various alternative formulations have been introduced, and it 
is now difficult to say where the definitive account may be found. Probability theory is built on three axioms or laws that define the behaviour of a probability measure, which may be
used as an estimate of the degree to which an uncertain event is likely to occur. They are:
\begin{enumerate}[i]
    \item {Convexity Law: $0 \leq Pr(A | H) \leq 1$}
    \item {Addition Law: $Pr(A \cup B |  H) = Pr(A | H) + Pr(B | H)$}
    \item {Multiplication Law: $Pr(A \cap B | H) = Pr(A | H) . Pr(B | A \cap H)$}
\end{enumerate}
\subsection{Aleatory and Epistemic Opinions}

\mycite{[Lecture Slides 4]}

Aleatory Uncertainty, which is the same as statistical uncertainty, expresses that we do not know the outcome each time we run the same experiment. we only know the long-term relative frequency of outcomes. An \textit{aleatory opinion} applies to a variable governed by a frequentist process, and that represents the (uncertain) likelihood of values of the variable in any unknown past or future instance of the process. 

Epistemic Uncertainty, aka systematic uncertainty, expresses that we could in principle know the outcome of a specific or future or past event, but that we do not have enough evidence to know it exactly. An \textit{epistemic opinion} applies to a variable that is assumed to be non-frequentist, and that represents the (uncertain) likelihood of values of the variable in a specific unknown past or future instance. 

In traditional Bayesian theory, the difference between aleatory and epistemic uncertainty is mostly philosophical and has no practical implication for modelling and analysing real situations, because the two types of opinions are formally and syntactically indistinguishable. In subjective logic however, the difference between aleatory and epistemic opinions is syntactically explicit, in the sense that epistemic opinions are uncertainty-maximised, whereas aleatory opinions can have arbitrary relative levels of uncertainty.

\section{Beta and Dirichlet Probability Density Functions}
The below definitions were obtained from \mycite{Subjective Logic: A Formalism for Reasoning under Uncertainty, Audun Jøsang, Chapter 3}
\subsection{Beta PDFs}
The Beta PDF is a probability density function denoted $Beta(p(x),\alpha,\beta)$ with variable $p(x)$, and two ‘strength parameters’ $\alpha$ and $\beta$. The Beta PDF is defined below:

Assume a binary domain $\mathbb{X} = \{x, \overline{x}\}$ and a random variable $X in \mathbb{X}$. Let $p$ denote the continuous probability function $p : X \rightarrow [0,1]$ where $p(x) + p(\overline{x}) = 1$.

The parameter $\alpha$ represents evidence/observations of $X = x$ and the parameter $\beta$ represents evidence/observations of $X = \overline{x}$. With $p_x$ as variable, the Beta probability density function Beta$(p_x, \alpha, \beta)$ is the function expressed as:
$$ 
    Beta(p_x, \alpha, \beta) : [0, 1] \rightarrow \mathbb{R}_{\geq 0}
$$
$$
    Beta(p_x, \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} \left(p_x\right)^{\alpha - 1}\left(1 - p_x\right)^{\beta - 1}, \alpha > 0, \beta > 0
$$

The PDF is normalized under the integration,

$$\int_{0}^{1} Beta(p, \alpha, \beta)dp = 1$$

Assume that $x$ represents a frequentist event, such as getting heads when flipping a coin. Let $r_x$ denote the number of observations 

$$\alpha = r_x +  a_xW$$

$$\beta = s_x + (1 - a_x)W$$    

Using the $\alpha$ and $\beta$ parameters, we can express Beta PDF as an evidence notation,

$$
Beta^e(p_x, r_x, s_x, a_x) = \frac{\Gamma(r_x + s_x + W)}{\Gamma(r_x + a_xW) \Gamma(s_x + (1 - a_x)W)}\left(p_x\right)\left(1 - p_x\right)^{s_x + (1 - a_x)W - 1}
$$

The expected probability $E(x)$ as a function of Beta PDF parameters is 
$$
E(x) = \frac{\alpha}{\alpha + \beta} = \frac{r_x + a_xW}{r_x + s_x + W}
$$
The traditional interpretation of probability
as likelihood of events gets a richer expression through probability density, which
can be interpreted as second-order probability. This interpretation is the basis for
mapping (high) probability density in Beta PDFs into (high) belief mass in opinions, through bijective mapping. As a consequence, flat probability density in Beta PDFs is represented as uncertainty in opinions.

The Beta PDF is important in subjective logic, because a bijective mapping can
be defined between the projected probability of a binomial opinion and the expected
probability of a Beta PDF.

The bijective mapping between a binomial opinion and a Beta PDF emerges from
the intuitive requirement that $P(x) = E(x)$, i.e. that the projected probability of a
binomial opinion must be equal to the expected probability of a Beta PDF.

Let \opinion{x}{b_x}{d_x}{u_x}{a_x} be a binomial opinion and let $p(x)$ be a probability distribution, both over the same binomial random variable $X$. Let $Beta^e(p_x, r_x, s_x, a_x)$ be a Beta PDF. The opinion $\omega_x$ and the Beta PDF $Beta^e(p_x, r_x, s_x, a_x)$ are equivalent as follows:

For $u_x \neq 0$:

$$
\begin{cases}
    b_x = \frac{r_x}{W + r_x + s_x}\\
    d_x = \frac{s_x}{W + r_x + s_x}\\
    u_x = \frac{W}{W + r_x + s_x}\\
\end{cases}
\Leftrightarrow
\begin{cases}
    r_x = \frac{b_xW}{u_x}\\
    s_x = \frac{d_xW}{u_x}\\
    1 = b_x + d_x + u_x\\
\end{cases}
$$

For $u_x = 0$:

$$
\begin{cases}
    b_x = \frac{r_x}{W + r_x + s_x}\\
    d_x = \frac{s_x}{W + r_x + s_x}\\
    u_x = \frac{W}{W + r_x + s_x}\\
\end{cases}
\Leftrightarrow
\begin{cases}
    r_x = b_x . \infty\\
    s_x = b_x . \infty\\
    1 = b_x + d_x\\
\end{cases}
$$
The below figure illustrates a binomial opinion \opinion{x}{0.52}{0.13}{0.35}{1} mapped into a Beta PDF graph.
\begin{center}
\includegraphics[width=6in]{images/add1viz.png}
\end{center}

The equivalence between binomial opinions and Beta PDFs is very powerful,
because subjective-logic operators (SL operators) can then be applied to Beta PDFs,
and statistics operations for Beta PDFs can be applied to opinions. In addition, it
makes it possible to determine binomial opinions from statistical observations.

\subsection{Dirichlet PDFs}
Let $\mathbb{X}$ be a domain consisting of $k$ mutually disjoint values. Let $\alpha_x$ represent the strength vector over the values of $\mathbb{X}$ and let $p_x$ denote the probability distribution over $\mathbb{X}$. With $p_x$ as a k-dimensional variable the Dirichlet PDF denoted $Dir(p_x, \alpha_x)$ is expressed as:
$$
Dir(p_x, \alpha_x) = \frac{\Gamma\left(\sum_{x \in \mathbb{X}} \alpha_X(x)\right)}{\prod_{x \in \mathbb{X}(\alpha_X(x))}}\prod_{x \in \mathbb{X}}p_x(x)^{a_X(x) - 1},   \alpha_X(x) \geq 0
$$

The strength vector $\alpha_X$ represents the prior, as well as the observation evidence. The non-informative prior weight is expressed as a constant W, and this weigth is distributed over all the outcomes as a function of base rate. As already mentioned, it is normally assumed that $W = 2$.

Evidence representation in Dirichlet PDF can be done using the evidence vector $r_x$, base rate distribution $a_x$ and non-informative prior W can be done as below:

$$
Dir^e_x(p_x, r_x, a_x) = \frac{\Gamma\left(\sum_{x \in \mathbb{X}} (r_X(x) + a_X(x)W)\right)}{\prod_{x \in \mathbb{X}}(r_X(x) + a_X(x)W)}\prod_{x \in \mathbb{X}}p_x(x)^{(r_X(x) + a_X(x)W) - 1},   \alpha_X(x) \geq 0
$$
This notation is useful because it allows the determination of the probability densities over variables, where each value can have an arbitrary base rate.

The bijective mapping between $\omega_x$ and $Dir^e_x(p_x, r_x, a_x)$ is based on the requirement for equality between the projected probability distribution $P_x$ derived from $\omega_x$ and the expected probability distribution $E_x$ derived from $Dir^e_x(p_x, r_x, a_x)$. This requirement is expressed as:

$$
P_x = E_x
\Leftrightarrow
b_X(x) + a_X(x)u_X = \frac{r_X(x) + Wa_X(x)}{W + \sum_{x_j \in \mathbb{X}} r_X(x_j)}
$$

Therefore the bijective mapping can be described as below:

For $u_x \neq 0$:

$$
\begin{cases}
    b_X(x) = \frac{r_X(x)}{W + \sum_{x_j \in \mathbb{X}} r_X(x_i)}\\
    u_X = \frac{r_X(x)}{W + \sum_{x_j \in \mathbb{X}} r_X(x_i)}\\
\end{cases}
\Leftrightarrow
\begin{cases}
    r_X(x) = \frac{Wb_X(x)}{u_x}\\
    1 = u_x + \sum_{x_j \in \mathbb{X}} b_X(x_i)\\
\end{cases}
$$

For $u_x = 0$:

$$
\begin{cases}
    b_X(x) = \frac{r_X(x)}{W + \sum_{x_j \in \mathbb{X}} r_X(x_j)}\\
    u_X = \frac{r_X(x)}{W + \sum_{x_j \in \mathbb{X}} r_X(x_j)}\\
\end{cases}
\Leftrightarrow
\begin{cases}
    r_X(x) = b_X(x) . \infty\\
    1 = \sum_{x_j \in \mathbb{X}} b_X(x_i)\\
\end{cases}
$$
\\
The below figure illustrates Dirichlet PDF over $(k - 1)$ dimensions
\begin{center}
    \includegraphics[width=3in]{images/dirich.png}
\end{center}
\section{Subjective Logic Operators}

All the below definitions were obtained from \mycite{Subjective Logic: A Formalism for Reasoning under Uncertainty, Audun Jøsang, Chapters 6 and 7}\\
\subsection{Complement Operator}
Assume the domain X = \{x, $\overline{x}$\} which can be
assumed to be binary or to be a binary partition of two subsets, where $\omega_x =
(b_x, d_x, u_x, a_x)$ is a binomial opinion about x. Its complement is the binomial opinion
$\omega_{\overline{x}}$ expressed as
$$
\omega_{\overline{x}}: 
\begin{cases}
    b_{\overline{x}} = d_x\\    
    d_{\overline{x}} = b_x\\
    u_{\overline{x}} = u_x\\
    a_{\overline{x}} = 1 - a_x
\end{cases}
$$
The complement operator corresponds to binary logic NOT, and to complement
of probabilities.

Complement Example 1:
Input data: 
\opinion{x}{0}{0.64}{0.35}{0.37}
\begin{center}
\includegraphics[width=3in]{images/comp1.png}
\end{center}
\hrulefill\\
\needspace{5\baselineskip}
Complement Example 2:
Input data: 
\opinion{x}{0}{0}{1}{0.29}(Vacuous Opinion)
\begin{center}
\includegraphics[width=3in]{images/comp2.png}
\end{center}
\subsection{Addition}
Addition of opinions in subjective logic is a binary operator that takes opinions
about two mutually exclusive values (i.e. two disjoint subsets of the same domain)
as arguments, and outputs an opinion about the union of the values.\\
Let \opinion{x_1}{b_{x_1}}{d_{x_1}}{u_{x_1}}{a_{x_1}} and \opinion{x_2}{b_{x_2}}{d_{x_2}}{u_{x_2}}{a_{x_2}} be two binomial opinions. The sum of these two opinions can be expressed as:
$$
\omega_{(x_1 \cup x_2)}: 
\begin{cases}
    b_{(x_1 \cup x_2)} = b_{x_1} + b_{x_2}\\    
    d_{(x_1 \cup x_2)} = \frac{a_{x_1}(d_{x_1} - b_{x_2}) + a_{x_2}(d_{x_2} - b_{x_1})}{a_{x_1} + a_{x_2}}\\
    u_{(x_1 \cup x_2)} = u_x\\
    a_{(x_1 \cup x_2)} = 1 - a_x
\end{cases}
$$\\
Addition Example 1:\\
\begin{center}
    Input data: 
    \opinion{x}{0.16}{0.54}{0.3}{0.73}, 
    \opinion{y}{0.36}{0.21}{0.44}{0.39}\\
    \includegraphics[width=3in]{images/add1.png}
    \includegraphics[width=3in]{images/add1viz.png}
\end{center}
\hrulefill\\
\needspace{5\baselineskip}
Addition Example 2:
    \begin{center}
        Input data: 
        \opinion{x}{0}{0}{1}{0.36}, 
        \opinion{y}{0.1}{0.48}{0.43}{0.39}\\
        \includegraphics[width=3in]{images/add2.png}
        \includegraphics[width=3in]{images/add2viz.png}
    \end{center}
    \hrulefill\\
\needspace{5\baselineskip}
Addition Example 3:
    \begin{center}
        Input data: 
        \opinion{x}{0.5}{0.5}{0}{0.36} (Dogmatic), 
        \opinion{y}{0}{0}{1}{0.39} (Vacuous)\\
        \includegraphics[width=3in]{images/add3.png}
        \includegraphics[width=3in]{images/add3viz.png}
    \end{center}

\subsection{Subtraction}
The inverse operation to opinion addition is opinion subtraction. Since addition
of opinions yields the opinion about $x_1 \cup x_2$ from the opinions about disjoint subsets
of the domain, then the difference between the opinions about $x_1 \cup x_2$ and $x_2$ (i.e.
the opinion about $((x_1 \cup x_2)/x_2))$ can only be defined if $x_2 \subseteq (x_1 \cup x_2)$ where $x_2$ and
$(x_1 \cup x_2)$ are subsets of the domain X, i.e. the system must be in the state $(x_1 \cup x_2)$
whenever it is in the state $x_2$. The sum of these two opinions can be expressed as:
$$
\omega_{((x_1 \cup x_2)/x_2)}: 
\begin{cases}
    b_{((x_1 \cup x_2)/x_2)} = b_{(x_1 \cup x_2)} - b_{x_2}\\    
    d_{((x_1 \cup x_2)/x_2)} = \frac{a_{(x_1 \cup x_2)}(d_{(x_1 \cup x_2)} + b_{x_2}) - a_{x_2}(1 + b_{x_2} - b_{(x_1 \cup x_2)} - u_{x_2})}{a_{x_1} + a_{x_2}}\\
    u_{((x_1 \cup x_2)/x_2)} = \frac{a_{(x_1 \cup x_2)} u_{(x_1 \cup x_2)} - a_{x_2} u_{x_2}}{a_{(x_1 \cup x_2)} - a_{x_2}}\\
    a_{((x_1 \cup x_2)/x_2)} = a_{(x_1 \cup x_2)} - a_{x_2}
\end{cases}
$$\\
Subtraction Example 1:\\
\begin{center}
    Input data: 
    \opinion{x_1 \cup x_2}{0.16}{0.54}{0.3}{0.73}, 
    \opinion{x_2}{0.36}{0.21}{0.44}{0.39}\\
    \includegraphics[width=3in]{images/sub1.png}
    \includegraphics[width=3in]{images/sub1viz.png}
\end{center}
\hrulefill\\
\needspace{5\baselineskip}
Subtraction Example 2:
    \begin{center}
        Input data: 
        \opinion{x_1 \cup x_2}{0}{0}{1}{0.36}, 
        \opinion{x_2}{0.1}{0.48}{0.43}{0.39}\\
        \includegraphics[width=3in]{images/sub2.png}
        \includegraphics[width=3in]{images/sub2viz.png}
    \end{center}
    \hrulefill\\
\needspace{5\baselineskip}
Subtraction Example 3:
    \begin{center}
        Input data: 
        \opinion{x_1 \cup x_2}{0.5}{0.5}{0}{0.36} (Vacuous), 
        \opinion{x_2}{0}{0}{1}{0.39} (Dogmatic)\\
        \includegraphics[width=3in]{images/sub3.png}
        \includegraphics[width=3in]{images/sub3viz.png}
\end{center}

\subsection{Multiplication}
Let \opinion{x}{b_x}{d_x}{u_x}{a_x} and \opinion{y}{b_y}{d_y}{u_y}{a_y} be two independent binomial opinions on x and y respectively. The binomial opinion $\omega_{x \land y}$ on the conjunction $(x \land y)$ is:
$$
\omega_{x \land y}
\begin{cases}
    b_{x \land y} = b_xb_y+ \frac{(1 - a_x)a_yb_xu_y + a_x(1 - a_y)u_xb_y}{1 - a_xa_y}\\    
    d_{x \land y} = d_x + d_y - d_xd_y\\
    u_{x \land y} = u_xu_y+ \frac{(1 - a_x)a_yb_xu_y + a_x(1 - a_y)u_xb_y}{1 - a_xa_y}\\
    a_{x \land y} = a_xa_y
\end{cases}
$$\\
Multiplication Example 1:\\
\begin{center}
    Input data: 
    \opinion{x_1}{0.21}{0.37}{0.42}{0.54}, 
    \opinion{x_2}{0.55}{0.15}{0.3}{0.25}\\
    \includegraphics[width=3in]{images/mul1.png}
    \includegraphics[width=3in]{images/mul1viz.png}
\end{center}
\hrulefill\\
\needspace{5\baselineskip}
Multiplication Example 2:
    \begin{center}
        Input data: 
        \opinion{x_1}{0.66}{0.06}{0.29}{0.28}, 
        \opinion{x_2}{0}{0.29}{0.71}{0.55}\\
        \includegraphics[width=3in]{images/mul2.png}
        \includegraphics[width=3in]{images/mul2viz.png}
    \end{center}
    \hrulefill\\
\needspace{5\baselineskip}
Multiplication Example 3:
    \begin{center}
        Input data: 
        \opinion{x_1}{0.72}{0.28}{0}{0.72} (Dogmatic), 
        \opinion{x_2}{0}{0}{1}{0.44} (Vacuous)\\
        \includegraphics[width=3in]{images/mul3.png}
        \includegraphics[width=3in]{images/mul3viz.png}
\end{center}
\subsection{Co-Multiplication}
Let \opinion{x}{b_x}{d_x}{u_x}{a_x} and \opinion{y}{b_y}{d_y}{u_y}{a_y} be two independent binomial opinions on x and y respectively. The binomial opinion $\omega_{x \lor y}$ on the conjunction $(x \lor y)$ is:
$$
\omega_{x \lor y}
\begin{cases}
    b_{x \lor y} = d_x + d_y - d_xd_y\\
    d_{x \lor y} = b_xb_y+ \frac{a_x(1 - a_y)d_xu_y + (1 - a_x)a_yu_xd_y}{a_x + a_y - a_xa_y}\\    
    u_{x \lor y} = u_xu_y+ \frac{a_yd_xu_y+a_xu_xd_y}{a_x+a_y-a_xa_y}\\
    a_{x \lor y} = a_x + a_y - a_xa_y
\end{cases}
$$\\
Co-Multiplication Example 1:\\
\begin{center}
    Input data:
    \opinion{x_1}{0.16}{0.48}{0.35}{0.72}, 
    \opinion{x_2}{0.1}{0.49}{0.41}{0.3}\\
    \includegraphics[width=3in]{images/comul1.png}
    \includegraphics[width=3in]{images/comul1viz.png}
\end{center}
\hrulefill\\
\needspace{5\baselineskip}
Co-Multiplication Example 2:
    \begin{center}
        Input data: 
        \opinion{x_1}{0.02}{0.23}{0.75}{0.72}, 
        \opinion{x_2}{0.6}{0.19}{0.2}{0.24}\\
        \includegraphics[width=3in]{images/comul2.png}
        \includegraphics[width=3in]{images/comul2viz.png}
    \end{center}
    \hrulefill\\
\needspace{5\baselineskip}
Co-Multiplication Example 3:
    \begin{center}
        Input data: 
        \opinion{x_1}{0}{1}{0}{0.72} (Dogmatic), 
        \opinion{x_2}{0}{0}{1}{0.45} (Vacuous)\\
        \includegraphics[width=3in]{images/comul3.png}
        \includegraphics[width=3in]{images/comul3viz.png}
\end{center}
\subsection{Division}
The inverse operation to binomial multiplication is binomial division. The quotient
of opinions about propositions x and y represents the opinion about a proposition z
which is independent of y such that $\omega_x = \omega_{y \land z}$.

Let \opinion{x}{b_x}{d_x}{u_x}{a_x} and \opinion{y}{b_y}{d_y}{u_y}{a_y} be two independent binomial opinions on x and y respectively.
The division of $\omega_x$ by $\omega_y$ produces the quotient opinion: \opinion{x \overline{\land} y}{b_{x \overline{\land} y}}{d_{x \overline{\land} y}}{u_{x \overline{\land} y}}{a_{x \overline{\land} y}}
$$
\omega_{x \overline{\land} y}
\begin{cases}
    b_{x \overline{\land} y} = \frac{a_y(b_x + a_xu_x)}{(a_y - a_x)(b_y + a_yu_y)} - \frac{a_x (1 - d_x)}{(a_y - a_x)(1 - d_y)}\\
    d_{x \overline{\land} y} = \frac{d_x - d_y}{1 - d_y}\\
    u_{x \overline{\land} y} = \frac{a_y (1 - d_x)}{(a_y - a_x)(1 - d_y)} - \frac{a_y(b_x + a_xu_x)}{(a_y - a_x)(b_y + a_yu_y)}\\
    a_{x \overline{\land} y} = \frac{a_x}{a_y}
\end{cases}
$$\\
where the following constraints are satisfied:
$$
Constraints
\begin{cases}
    b_x \geq \frac{a_x(1 - a_y) (1 - d_x) b_y}{(1 - a_x)a_y (1_dy)}\\
    d_x \geq d_y\\
    u_x = \geq \frac{u_x(1 - a_y) (1 - d_x) b_y}{(1 - a_x) (1_dy)}\\
    a_x < a_y
\end{cases}
$$\\
Division Example 1:\\
\begin{center}
    Input data:
    \opinion{x_1}{0.25}{0.31}{0.44}{0.72}, 
    \opinion{x_2}{0.66}{0.12}{0.22}{0.87}\\
    \includegraphics[width=3in]{images/div1.png}
    \includegraphics[width=3in]{images/div1viz.png}
\end{center}
\hrulefill\\
\needspace{5\baselineskip}
Division Example 2:
    \begin{center}
        Input data: 
        \opinion{x_1}{0.24}{0.64}{0.12}{0.72}, 
        \opinion{x_2}{0.52}{0.48}{0}{0.81} (Dogmatic)
        \includegraphics[width=3in]{images/div2.png}
        \includegraphics[width=3in]{images/div2viz.png}
    \end{center}
    \hrulefill\\
\needspace{5\baselineskip}
Division Example 3:
    \begin{center}
        Input data: 
        \opinion{x_1}{1}{0}{0}{0.72} (Dogmatic), 
        \opinion{x_2}{0.34}{0.36}{0.3}{0.81}\\
        \includegraphics[width=3in]{images/div3.png}
        It was not possible to obtain a visualization for this sample case.
\end{center}

\subsection{Co-Division}
The inverse operation to binomial co-multiplication is binomial co-division. The co-quotient
of opinions about propositions x and y represents the opinion about a proposition z
which is independent of y such that $\omega_x = \omega_{y \land z}$.

Let \opinion{x}{b_x}{d_x}{u_x}{a_x} and \opinion{y}{b_y}{d_y}{u_y}{a_y} be two independent binomial opinions on x and y respectively.
The division of $\omega_x$ by $\omega_y$ produces the coquotient opinion: \opinion{x \overline{\lor} y}{b_{x \overline{\lor} y}}{d_{x \overline{\lor} y}}{u_{x \overline{\lor} y}}{a_{x \overline{\lor} y}}
$$
\omega_{x \overline{\lor} y}
\begin{cases}
    b_{x \overline{\lor} y} = \frac{b_x - b_y}{1 - b_y}\\
    u_{x \overline{\lor} y} = \frac{(1 - a_y)(1 - b_x)}{(a_x - a_y)(1 - b_y)} - \frac{(1 - a_y) (1 - b_x)}{(a_x - a_y)(1 - b_y)}\\
    d_{x \overline{\lor} y} = \frac{(1 - a_y) (1 - b_x)}{(a_x - a_y)(1 - b_y)} - \frac{(1 - a_y)(d_x + (1 - a_x)u_x)}{(a_x - a_y)(1 - b_y)}\\
    a_{x \overline{\lor} y} = \frac{a_x - a_y}{1 - a_y}
\end{cases}
$$\\
where the following constraints are satisfied:
$$
Constraints
\begin{cases}
    d_x \geq \frac{(1 - a_x)a_y(1 - b_x)d_y}{a_x(1 - a_y)(1 - b_y)}\\
    u_x \geq \frac{a_y(1 - b_x) u_y}{a_x (1 - b_y)}\\
    b_x \geq b_y\\
    a_x > a_y
\end{cases}
$$\\
Co-Division Example 1:\\
\begin{center}
    Input data:
    \opinion{x_1}{0.2}{0.43}{0.37}{0.72}, 
    \opinion{x_2}{0.09}{0.59}{0.31}{0.26}\\
    \includegraphics[width=3in]{images/codiv1.png}
    \includegraphics[width=3in]{images/codiv1viz.png}
\end{center}
\hrulefill\\
\needspace{5\baselineskip}
Co-Division Example 2:
    \begin{center}
        Input data: 
        \opinion{x_1}{0.2}{0.43}{0.37}{0.66}, 
        \opinion{x_2}{0.09}{0.59}{0.31}{0.79}\\
        \includegraphics[width=3in]{images/codiv2.png}
        It was not possible to obtain a visualization for this sample case.
    \end{center}
\needspace{5\baselineskip}
Co-Division Example 3:
    \begin{center}
        Input data: 
        \opinion{x_1}{0.5}{0.32}{0.18}{0.26}, 
        \opinion{x_2}{0.33}{0.14}{0.53}{0.35}\\
        \includegraphics[width=3in]{images/codiv3.png}
        It was not possible to obtain a visualization for this sample case.
\end{center}
\section{Approaches to Reasoning}
Various parts of the below essay have been adapted from \mycite{A Review of Uncertainty Handling Formalisms, Simon Parsons and Anthony Hunter}.\\
Over the decades, various approaches to reasoning have been developed, each of which provide a formalism to handle uncertainty and ignorance. Uncertainty is generally considered to be a sub jective measure of the certainty of something and is
thus modelled using a numerical value, typically between 0 and 1 with 0 denoting falsity and 1 denoting truth. Absence is the occurrence of missing facts,
and is usually dealt with by essentially logical methods. The wide acceptance of
the suggestion that uncertainty and absence are essentially different, and must
therefore be handled by different techniques has lead to a schism in approximate
reasoning between the "symbolic camp" who use logical methods to deal with
absence and the "numerical camp" who use quantitative measures to deal with
uncertainty. Let us look at these approaches in detail and compare their advantages and disadvantages with Subjective Logic as proposed by Prof. Jøsang.
\subsection{Numerical Approaches}
Numerical Approaches towards handling uncertainty can be divided into three categories: Probability Theory, Possibility Theory and Evidence Theory. Even though these theories may appear significantly different, they are remarkably similar. The basic problem is how to weigh up the degree to which several uncertain
events are believed to occur so that the most believed may be unambiguously identified. The basis on which the "belief" is assigned is a contentious issue,
though all the theories that we shall consider assume allocation by an assignment
function that distributes belief to possible events under consideration. Belief may
be distributed on the basis of statistical information, physical possibility, or purely subjective assessment by an expert or otherwise. The belief
assigned is a number between 0 and 1, with 0 being the belief assigned to a fact
that is known to be false, and 1 the belief assigned to a fact known to be
true. The infinite number of degrees of belief between the limits represent various
shades of uncertainty.\\
\subsubsection{Probability Theory}
Probability theory has existed in one form or another for several hundred years.
During this time various alternative formulations have been introduced, and it 
is now difficult to say where the definitive account may be found. Probability theory is built on three axioms or laws that define the behaviour of a probability measure, which may be
used as an estimate of the degree to which an uncertain event is likely to occur. They are:
\begin{enumerate}[i]
    \item {Convexity Law: $0 \leq Pr(A | H) \leq 1$}
    \item {Addition Law: $Pr(A \cup B |  H) = Pr(A | H) + Pr(B | H)$}
    \item {Multiplication Law: $Pr(A \cap B | H) = Pr(A | H) . Pr(B | A \cap H)$}
\end{enumerate}
The above laws form the basis for another set of important laws that define the use of probability theory in artificial intelligence:
\begin{enumerate}[i]
    \item {Jeffrey's rule: $\sum\limits_{i = 1, ..., n}Pr(A|B_i)Pr(B_i)$}
    \item {Bayes' Theorem: $Pr(A|B) = \frac{Pr(B|A) . Pr(A)}{Pr(B)}$}
\end{enumerate}
\subsubsection{Evidence Theory}
Evidence Theory, otherwise known as Dempster Shafer Theory, was an attempt at remedying the limitations of probability theory. The theory deals with a frame of discernment: the set of elements $\theta = {\theta_1, \theta_2}$ which is assigned a *belief mass*, wherein:

$$
m(\emptyset) = 0\\
$$
$$
\sum\limits_{A \subseteq \theta} m(A) = 1
$$

We can define the belief we have in a subset A as the sum of all the probability masses that support its constituents:
$$
Bel(A) = \sum\limits_{B \subseteq A} m(B)
$$
$$
Pl(A) = \sum\limits_{B \cap A \neq \emptyset} m(B)
$$
$$
Pl(A) = 1 - Bel(\neg A)
$$

The interval $[Bel(A), Pl(A)]$ can be considered to be a measure of our ignorance about A, and can vary from zero when we have the same degree of belief in A as would be generated by probability theory, to 1 when A has belief 0 and plausibility 1. This means that no mass is assigned to A or any of its subsets, but equally no mass is assigned to $\neg A$.

\subsubsection{Possibility Theory}
The economist G.L.S Shackle proposed a formalism wherein the calculus of \textit{potential surprise} was defined as a subjective of the degree by which the observer would be surprised. If an event is entirely possible, then there would be no surprise attached to its occurence.

A fuzzy set is a set whose membership is not absolute, but a matter of degree, such as the set of tall people. A fuzzy set F is characterised by the membership function $\mu_F$ which specifies the degree to which each object in a universe $U$ is a member of $F$. The assignment of a value u to $X$ has the form:
$$
X = u : \mu_F(u)
$$

A possibility distribution function $\pi_x$ which is defined to be equal to the membership function of F: 
$$
\pi_x = \mu_F
$$
Thus $\pi_x$, the possibility that $X = u$ is taken to be equal to $\mu_F(u)$.
\subsubsection{Limitations of numerical techniques}
Parsons and Hunter describe three limitations of numerical techniques and how various mathematicians have pointed them out:
\begin{itemize}
    \item Lack of development of fuzzy sets and possibility theory
    \item Interpretation of results as they are in the form of numbers
    \item Computational expense
\end{itemize} 
\subsection{Symbolic Approaches}
Nonmonotonic logics were designed with an intention to create sound formal mechanisms for reasoning in such a way that they overcome the limits of numerical approaches. There are many problems in AI that cannot be solved using classical logic, for example, problems that require "commonsense".

Nonmonotonic approaches can be divided into three categories: Default Logic, Argumentation and Truth Maintenance Systems

\subsubsection{Default Logic}
Default logic allows the modelling of prototypical reasoning by allowing special inference rules, known as default rules to be added to a standard first order logic.

Given a set of default rules D and a first order theory W, it is possible to define an extension of the default theory as the closure of W plus a maximal consistent set of consequences of D. An extension E of a default theory is a minimal set of beliefs that contain W are deductively closed and maximally consistent with the rules in D. Thus if S is a sentence then, $\Gamma(S)$ is a minimal set such that:

$$
W \subseteq \Gamma(S)
$$
$$
Th(\Gamma(S)) = \Gamma(S)
$$
where Th(T) is the deductive closure of T.

Despite the maturity of the theoretical work on default logic, there are as yet few applications because there has been less attention paid to providing prospective application builders with useful tools for using default logic.
\subsubsection{Argumentation}
An argument can be structured so that from facts a qualified claim can be argued only if:
\begin{enumerate}[1]
    \item there is some warrant that can be used with the facts to logically derive the claim
    \item there is no other argument that would act as a rebuttal of the claim
\end{enumerate}

An argument can be modelled by a pair $(\phi, \alpha)$ where $\phi$ is a set of forumlae, and $\alpha$ is a formula derived as a conclusion from the assumptions $\phi$ also known as grounds of the argument.

Argumentation can be used to handle uncertain information by extending the pair to a triple in which the third quantity is a measure of the degree to which $\alpha$ is believed to be true.

\subsubsection{Truth Maintenance System}
A Truth Maintenance System records information about each inference that is generated from a set of assumptions. There are two types of TMS:
\begin{itemize}
    \item Justification Based Truth Maintenance System: When an inconsistency in stored rules is detected, some external system is invoked to resolved the inconsistency.
    \item Assumption Based Truth Maintenance System: inconsistency is handled by creating new consistent subsets and identifying which inferences may be made from them.
\end{itemize}
\subsection{Subjective Logic}
The below definitions and diagram were obtained from \mycite{Subjective Logic: A Formalism for Handling Uncertainty, Audun Jøsang, 2016}

In binary logic a proposition about the state of the world must be either true or
false, which fits well with an assumed objective world. Probability calculus takes
argument probabilities in the range [0,1], and hence to some extent reflects subjectivity by allowing propositions to be partially true. However, we are often unable to
estimate probabilities with confidence because we lack the necessary evidence. A
formalism for expressing degrees of uncertainty about beliefs is therefore needed in
order to more faithfully reflect the perceived world in which we are all immersed.
In addition, whenever a belief about a proposition is expressed, it is always done by
an individual, and it can never be considered to represent a general and objective
belief. It is therefore necessary that the formalism also includes belief ownership in
order to reflect the fundamental subjectivity of all beliefs.

In subjective logic, we can represent an opinion as \opinion{x}{b_x}{d_x}{u_x}{a_x}, where $b_x$ represents belief mass distribution, $d_x$ represents disbelief, $u_x$ represents uncertainty mass and $a_x$ represents base rate. 
\begin{center}
    \includegraphics[width=6in]{images/barycentric.png}
\end{center}
The advantages of using subjective logic are that real-world situations can be
realistically modelled with regard to how those situations are perceived, and that conclusions more correctly reflect the ignorance and uncertainties that necessarily result from partially uncertain input arguments. Subjective logic has the advantage of providing advanced operators for Dirichlet PDFs, for which no practical analytical solutions previously existed. It should be mentioned that the simplicity of some SL operators comes at the cost of allowing those operators to be approximations of the analytically correct operators. 
\end{document}